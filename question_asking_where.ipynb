{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "textfile = \"data/set4/a7.txt\"\n",
    "#put entire text file into a list of sentences\n",
    "def get_text(textFile):\n",
    "\ttext = []\n",
    "\twith open(textFile, \"r\") as f:\n",
    "\t\tfor line in f:\n",
    "\t\t\ttext = text + sent_tokenize(line)\n",
    "\treturn text\n",
    "text = get_text(textfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [('h', 'X', 'LS', 'ROOT', False)], 1: [('e', 'VERB', 'VB', 'ROOT', False)], 2: [('l', 'NOUN', 'NN', 'ROOT', False)], 3: [('l', 'NOUN', 'NN', 'ROOT', False)], 4: [('o', 'INTJ', 'UH', 'ROOT', False)], 5: [(' ', 'SPACE', '_SP', 'ROOT', False)], 6: [('m', 'VERB', 'VBP', 'ROOT', False)], 7: [('y', 'PROPN', 'NNP', 'ROOT', False)], 8: [(' ', 'SPACE', '_SP', 'ROOT', False)], 9: [('n', 'ADV', 'RB', 'ROOT', False)], 10: [('a', 'DET', 'DT', 'ROOT', True)], 11: [('m', 'VERB', 'VBP', 'ROOT', False)], 12: [('e', 'VERB', 'VB', 'ROOT', False)], 13: [(' ', 'SPACE', '_SP', 'ROOT', False)], 14: [('i', 'PRON', 'PRP', 'ROOT', True)], 15: [('s', 'VERB', 'VBZ', 'ROOT', False)], 16: [(' ', 'SPACE', '_SP', 'ROOT', False)], 17: [('L', 'NOUN', 'NN', 'ROOT', False)], 18: [('a', 'DET', 'DT', 'ROOT', True)], 19: [('u', 'NOUN', 'NN', 'ROOT', False)], 20: [('r', 'NOUN', 'NN', 'ROOT', False)], 21: [('a', 'DET', 'DT', 'ROOT', True)]}\n"
     ]
    }
   ],
   "source": [
    "print(pos_tag_lst(\"hello my name is Laura\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (<ipython-input-3-deafc25b4eb5>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-deafc25b4eb5>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    print(doc)\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "def pos_tag_lst(text):\n",
    "\t#list of sentences\n",
    "\tPOS_tag_dict = dict()\n",
    "\tfor i,line in enumerate(text):\n",
    "\t\ttags = []\n",
    "\t\tdoc = nlp(str(line))\n",
    "        print(doc)\n",
    "\t\tfor token in doc:\n",
    "#             print(doc)\n",
    "#             print(token)\n",
    "\t\t\ttags.append((token.text, token.pos_, token.tag_, token.dep_, token.is_stop))\n",
    "\t\tif len(tags) != 0:\n",
    "\t\t\tPOS_tag_dict[i] = tagsb\n",
    "\treturn POS_tag_dict\n",
    "\n",
    "def pos_tag_sentence(sentence):\n",
    "\t#list of sentences\n",
    "\tPOS_tag_dict = dict()\n",
    "\ttext = sentence.split()\n",
    "\tfor line in text:\n",
    "\t\ttags = []\n",
    "\t\tdoc = nlp(str(line))\n",
    "\t\tfor token in doc:\n",
    "\t\t\ttags.append((token.pos_, token.tag_, token.dep_, token.is_stop, ))\n",
    "\t\tif len(tags) != 0:\n",
    "\t\t\tPOS_tag_dict[token.text] = tags[0]\n",
    "\treturn POS_tag_dict\n",
    "\n",
    "#Token dict\n",
    "def dependency_dict(doc):\n",
    "\tout = dict()\n",
    "\troot = ''\n",
    "\tfor token in doc:\n",
    "\t\tout[token.text] = (token.dep_, token.head.text, token.head.pos_,[child for child in token.children])\n",
    "\t\tif token.dep_ == \"ROOT\":\n",
    "\t\t\troot = token.text\n",
    "\treturn out, root\n",
    "\n",
    "# NER tagging\n",
    "def ner_tag(text):\n",
    "\tNER_tag_dict = dict()\n",
    "\tfor i,line in enumerate(text):\n",
    "\t\ttags = []\n",
    "\t\tdoc = nlp(str(line))\n",
    "\n",
    "\t\tfor ent in doc.ents:\n",
    "\t\t\t# print(ent.text +'-' + ent.label_ + '\\n')\n",
    "\t\t\ttags.append(ent.text +'-' + ent.label_)\n",
    "\t\tif len(tags) != 0:\n",
    "\t\t\tNER_tag_dict[i] = tags\n",
    "\treturn NER_tag_dict\n",
    "\n",
    "def ner_tag_sentence(sentence):\n",
    "\tdoc = nlp(str(sentence))\n",
    "\tNER_tag_dict = dict()\n",
    "\ttags = []\n",
    "\tfor ent in doc.ents:\n",
    "\t\t# print(ent.text +'-' + ent.label_ + '\\n')\n",
    "\t\tNER_tag_dict[ent.text] = ent.label_\n",
    "\treturn NER_tag_dict\n",
    "\n",
    "\n",
    "#check tense of verb\n",
    "def check_tense(root, pos_dict):\n",
    "\ttag = pos_dict[root][1]\n",
    "\tif tag == \"VB\":\n",
    "\t\treturn \"do\"\n",
    "\telif tag == \"VBD\":\n",
    "\t\treturn \"did\"\n",
    "\telif tag == \"VBG\":\n",
    "\t\treturn \"doing\"\n",
    "\telif tag == \"VBN\":\n",
    "\t\treturn \"done\"\n",
    "\telif tag == \"VBP\":\n",
    "\t\treturn \"do\"\n",
    "\telif tag == \"VBZ\":\n",
    "\t\treturn \"does\"\n",
    "\telse:\n",
    "\t\treturn None\n",
    "\n",
    "# return dictionary of lemmas in sentence\n",
    "def getTokenLemma(nlp_doc):\n",
    "\tlemmas = {}\n",
    "\tfor token in nlp_doc:\n",
    "\t\tlemmas[str(token)] = token.lemma_\n",
    "\treturn lemmas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pos_tag_sentence(sentence):\n",
    "#     #list of sentences\n",
    "#     POS_tag_dict = dict()\n",
    "#     text = sentence.split()\n",
    "#     for i,line in enumerate(text):\n",
    "#         tags = []\n",
    "#         doc = nlp(str(line))\n",
    "#         for token in doc:\n",
    "#             tags.append((token.text, token.pos_, token.tag_, token.dep_, token.is_stop, ))\n",
    "#         if len(tags) != 0:\n",
    "#             POS_tag_dict[i] = tags\n",
    "#     return POS_tag_dict\n",
    "def pos_tag_sentence(sentence):\n",
    "\t# list of sentences\n",
    "\tPOS_tag_dict = dict()\n",
    "\ttext = sentence.split()\n",
    "\tfor line in text:\n",
    "\t\ttags = []\n",
    "\t\tdoc = nlp(str(line))\n",
    "\t\tfor token in doc:\n",
    "\t\t\ttags.append((token.pos_, token.tag_, token.dep_, token.is_stop,))\n",
    "\t\tif len(tags) != 0:\n",
    "\t\t\tPOS_tag_dict[token.text] = tags[0]\n",
    "\treturn POS_tag_dict\n",
    "\n",
    "def pos_tag_lst(text):\n",
    "    #list of sentences\n",
    "    POS_tag_dict = dict()\n",
    "    for i,line in enumerate(text):\n",
    "        tags = []\n",
    "        doc = nlp(str(line))\n",
    "        for token in doc:\n",
    "            tags.append((token.text, token.pos_, token.tag_, token.dep_, token.is_stop))\n",
    "        if len(tags) != 0:\n",
    "            POS_tag_dict[i] = tags\n",
    "    return POS_tag_dict\n",
    "\n",
    "#Token dict \n",
    "def dependency_dict(doc):\n",
    "    out = dict()\n",
    "    root = ''\n",
    "    for token in doc:\n",
    "        out[token.text] = (token.dep_, token.head.text, token.head.pos_,[child for child in token.children])\n",
    "        if token.dep_ == \"ROOT\":\n",
    "            root = token.text\n",
    "    return out, root\n",
    "\n",
    "def ner_tag_sentence(sentence):\n",
    "    doc = nlp(str(sentence))\n",
    "    NER_tag_dict = dict()\n",
    "    tags = []\n",
    "    for ent in doc.ents:\n",
    "        # print(ent.text +'-' + ent.label_ + '\\n')\n",
    "        NER_tag_dict[ent.text] = ent.label_\n",
    "    return NER_tag_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HowOftenQ(sentence, ner_tag_dict, dependency_dict, root):\n",
    "    date = \"\"\n",
    "    output = \"\"\n",
    "    clause = \"\"\n",
    "    sentence = sentence[:-1]\n",
    "    for k in ner_tag_dict.keys():\n",
    "        if ner_tag_dict[k] == 'DATE':\n",
    "            date = k\n",
    "    if date == \"\": return\n",
    "    date_lst = date.split()\n",
    "    sentence_lst = sentence.split()\n",
    "    root_lst_ind = sentence_lst.index(root)\n",
    "    root_ind = sentence.index(root)\n",
    "    date_ind = sentence.index(date)\n",
    "    if date_ind < root_ind:\n",
    "        word_in_front_of_root = sentence_lst[root_lst_ind - 1]\n",
    "        if token_Dict[word_in_front_of_root][0] == 'auxpass':\n",
    "            sentence_lst[root_lst_ind - 1] = sentence_lst[root_lst_ind - 2]\n",
    "            sentence_lst[root_lst_ind - 2] = word_in_front_of_root\n",
    "        else:\n",
    "            sentence_lst[root_lst_ind] = nlp(root)[0].lemma_\n",
    "            if pos_tag_sentence(root)[0][0][2] in (\"VBD\", \"VBN\"):\n",
    "                sentence_lst.insert(root_lst_ind-1,\"did\")\n",
    "            else: sentence_lst.insert(root_lst_ind-1,\"does\")\n",
    "        for i in date_lst:\n",
    "            sentence_lst.remove(i)\n",
    "        output = \"How long \" + \" \".join(sentence_lst)\n",
    "    else:\n",
    "        for seg in sentence.split(',', 1):\n",
    "            if date in seg: clause = seg\n",
    "        if root_ind != 0:\n",
    "            word_in_front_of_root = sentence_lst[root_lst_ind - 1] \n",
    "            word_after_root = sentence_lst[root_lst_ind + 1]\n",
    "            prep_ind = sentence.index(word_after_root)\n",
    "            if token_Dict[word_after_root][0] != 'prep': word_after_root = \"\"\n",
    "            #if it's passive tense\n",
    "            if token_Dict[word_in_front_of_root][0] == 'auxpass':\n",
    "                output = \"How long \" + word_in_front_of_root + \" \" + clause.split(word_in_front_of_root,1)[0].lower() +  sentence[root_ind:prep_ind+len(word_after_root)]\n",
    "            else:\n",
    "                #if it's past tense\n",
    "                if pos_tag_sentence(root)[0][0][2] in (\"VBD\", \"VBN\"):\n",
    "                    output = \"How long\" + \" did \" + clause.split(root,1)[0].lower() + nlp(root)[0].lemma_ + sentence[root_ind+len(root):prep_ind+len(word_after_root)]\n",
    "                #if it's not past tense\n",
    "                else:\n",
    "                    output = \"How long\" + \" does \" + clause.split(root,1)[0].lower() + nlp(root)[0].lemma_ + sentence[root_ind+len(root):prep_ind+len(word_after_root)]\n",
    "    output = ' '.join(output.split()) + \"?\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Four months after Harris's death, Cuarón chose Gambon as his replacement.\"\n",
    "#sentence = \"With Prisoner of Azkaban, production of the Harry Potter films was switched to an eighteen-month cycle.\"\n",
    "# sentence = \"Harry Potter and the Prisoner of Azkaban is a 2004 fantasy film directed by Alfonso Cuaron and distributed by Warner Bros. Pictures.\"\n",
    "doc = nlp(sentence)\n",
    "token_Dict, root = dependency_dict(doc)\n",
    "ner_tag_dict = ner_tag_sentence(sentence)\n",
    "pos_tag_dict = pos_tag_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Four': ('NUM', 'CD', 'ROOT', True),\n",
       " 'months': ('NOUN', 'NNS', 'ROOT', False),\n",
       " 'after': ('ADP', 'IN', 'ROOT', True),\n",
       " \"'s\": ('PROPN', 'NNP', 'ROOT', False),\n",
       " ',': ('NOUN', 'NN', 'ROOT', False),\n",
       " 'Cuarón': ('PROPN', 'NNP', 'ROOT', False),\n",
       " 'chose': ('VERB', 'VBD', 'ROOT', False),\n",
       " 'Gambon': ('PROPN', 'NNP', 'ROOT', False),\n",
       " 'as': ('ADP', 'IN', 'ROOT', True),\n",
       " 'his': ('PRON', 'PRP$', 'ROOT', True),\n",
       " '.': ('NOUN', 'NN', 'ROOT', False)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [('is', 'AUX', 'VBZ', 'ROOT', True)]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag_sentence(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [('Four', 'NUM', 'CD', 'ROOT', True)],\n",
       " 1: [('months', 'NOUN', 'NNS', 'ROOT', False)],\n",
       " 2: [('after', 'ADP', 'IN', 'ROOT', True)],\n",
       " 3: [('Harris', 'PROPN', 'NNP', 'ROOT', False),\n",
       "  (\"'s\", 'PART', 'POS', 'case', True)],\n",
       " 4: [('death', 'NOUN', 'NN', 'ROOT', False),\n",
       "  (',', 'PUNCT', ',', 'punct', False)],\n",
       " 5: [('Cuarón', 'PROPN', 'NNP', 'ROOT', False)],\n",
       " 6: [('chose', 'VERB', 'VBD', 'ROOT', False)],\n",
       " 7: [('Gambon', 'PROPN', 'NNP', 'ROOT', False)],\n",
       " 8: [('as', 'ADP', 'IN', 'ROOT', True)],\n",
       " 9: [('his', 'PRON', 'PRP$', 'ROOT', True)],\n",
       " 10: [('replacement', 'NOUN', 'NN', 'ROOT', False),\n",
       "  ('.', 'PUNCT', '.', 'punct', False)]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How long does harry potter and the prbe?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HowOftenQ(sentence, ner_tag_dict, token_Dict, root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whereQ(sentence, dep_dict, root):\n",
    "    output = ''\n",
    "    verbs = ['was', 'is', 'were']\n",
    "    foundVerb = False\n",
    "    foundVerbInd = 0\n",
    "    # find tense \n",
    "    pos_tags = pos_tag_sentence(sentence)\n",
    "    seenWhere = False\n",
    "    foundWhereInd = 0\n",
    "    whereInd = 0\n",
    "    tense = None\n",
    "    for word in sentence.split():\n",
    "        if word == 'where':\n",
    "            seenWhere = True\n",
    "            foundWhereInd = whereInd\n",
    "            verb = dep_dict[word][1]\n",
    "            if pos_tags[verb][0] == 'VERB':\n",
    "                tense = check_tense(verb, pos_tags)\n",
    "            elif verb in verbs: # if tense is was, is, were\n",
    "                tense = verb\n",
    "                foundVerb = True\n",
    "                foundVerbInd = sentence.split().index(verb)\n",
    "            break\n",
    "        whereInd += 1\n",
    "    if tense == None: # not able to create question from sentence\n",
    "        return \"No question\"\n",
    "    output += f'Where {tense} '\n",
    "    ind = foundWhereInd\n",
    "    if foundVerb:\n",
    "        ind = foundVerbInd\n",
    "    for word in sentence.split()[ind+1:]:\n",
    "        output += word + \" \"    \n",
    "    return output[:-2] + \"?\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'This': ('nsubj', 'leads', 'VERB', []), 'leads': ('ROOT', 'leads', 'VERB', [This, trio, to, .]), 'the': ('det', 'dog', 'NOUN', []), 'trio': ('dobj', 'leads', 'VERB', [the]), 'to': ('prep', 'passage', 'NOUN', [Shack]), 'an': ('det', 'Animagus', 'PROPN', []), 'underground': ('amod', 'passage', 'NOUN', []), 'passage': ('pobj', 'to', 'ADP', [an, underground, to]), 'Shrieking': ('compound', 'Shack', 'PROPN', []), 'Shack': ('pobj', 'to', 'ADP', [the, Shrieking, ,, discover]), ',': ('punct', 'Sirius', 'PROPN', []), 'where': ('advmod', 'discover', 'VERB', []), 'they': ('nsubj', 'discover', 'VERB', []), 'discover': ('relcl', 'Shack', 'PROPN', [where, they, is]), 'that': ('mark', 'is', 'AUX', []), 'dog': ('nsubj', 'is', 'AUX', [the]), 'is': ('relcl', 'Sirius', 'PROPN', [who, Animagus]), 'actually': ('advmod', 'is', 'AUX', []), 'Sirius': ('attr', 'is', 'AUX', [,, is]), 'who': ('nsubj', 'is', 'VERB', []), 'Animagus': ('attr', 'is', 'VERB', [an]), '.': ('punct', 'leads', 'VERB', [])} leads\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This leads the trio to an underground passage to the Shrieking Shack, where they discover that the dog is actually Sirius, who is an Animagus.\"\n",
    "dep_dict1, root1 = dependency_dict(nlp(sentence))\n",
    "print(dep_dict1, root1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'He': ('nsubj', 'was', 'AUX', []), 'was': ('ROOT', 'was', 'AUX', [He, in, .]), 'in': ('prep', 'was', 'AUX', [underground]), 'the': ('det', 'underground', 'NOUN', []), 'underground': ('pobj', 'in', 'ADP', [the, ,, were]), ',': ('punct', 'underground', 'NOUN', []), 'where': ('advmod', 'were', 'VERB', []), 'there': ('expl', 'were', 'VERB', []), 'were': ('relcl', 'underground', 'NOUN', [where, there, lots]), 'lots': ('attr', 'were', 'VERB', [of]), 'of': ('prep', 'lots', 'NOUN', [tea]), 'tea': ('pobj', 'of', 'ADP', []), '.': ('punct', 'was', 'AUX', [])} was\n"
     ]
    }
   ],
   "source": [
    "sentence2 = \"He was in the underground, where there were lots of tea.\"\n",
    "dep_dict2, root2 = dependency_dict(nlp(sentence2))\n",
    "print(dep_dict2, root2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'He': ('PRON', 'PRP', 'ROOT', True),\n",
       " 'was': ('AUX', 'VBD', 'ROOT', True),\n",
       " 'in': ('ADP', 'IN', 'ROOT', True),\n",
       " 'the': ('DET', 'DT', 'ROOT', True),\n",
       " ',': ('ADV', 'RB', 'ROOT', False),\n",
       " 'where': ('ADV', 'WRB', 'ROOT', True),\n",
       " 'there': ('ADV', 'RB', 'ROOT', True),\n",
       " 'were': ('AUX', 'VBD', 'ROOT', True),\n",
       " 'lots': ('NOUN', 'NNS', 'ROOT', False),\n",
       " 'of': ('ADP', 'IN', 'ROOT', True),\n",
       " '.': ('NOUN', 'NN', 'ROOT', False)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag_sentence(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'This': ('DET', 'DT', 'ROOT', True),\n",
       " 'leads': ('VERB', 'VBZ', 'ROOT', False),\n",
       " 'the': ('DET', 'DT', 'ROOT', True),\n",
       " 'trio': ('NOUN', 'NN', 'ROOT', False),\n",
       " 'to': ('PART', 'TO', 'ROOT', True),\n",
       " 'an': ('DET', 'DT', 'ROOT', True),\n",
       " 'underground': ('ADV', 'RB', 'ROOT', False),\n",
       " 'passage': ('NOUN', 'NN', 'ROOT', False),\n",
       " 'Shrieking': ('VERB', 'VBG', 'ROOT', False),\n",
       " ',': ('PROPN', 'NNP', 'ROOT', False),\n",
       " 'where': ('ADV', 'WRB', 'ROOT', True),\n",
       " 'they': ('PRON', 'PRP', 'ROOT', True),\n",
       " 'discover': ('VERB', 'VB', 'ROOT', False),\n",
       " 'that': ('DET', 'DT', 'ROOT', True),\n",
       " 'dog': ('NOUN', 'NN', 'ROOT', False),\n",
       " 'is': ('AUX', 'VBZ', 'ROOT', True),\n",
       " 'actually': ('ADV', 'RB', 'ROOT', False),\n",
       " 'who': ('PRON', 'WP', 'ROOT', True),\n",
       " '.': ('PROPN', 'NNP', 'ROOT', False)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where do they discover that the dog is actually Sirius, who is an Animagus?\n"
     ]
    }
   ],
   "source": [
    "print(whereQ(sentence, dep_dict1, root1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where were lots of tea?\n"
     ]
    }
   ],
   "source": [
    "print(whereQ(sentence2, dep_dict2, root2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Asking- Checking Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the sentence contains certain NER tags\n",
    "#When - DATE\n",
    "#Who - PERSON\n",
    "#Where\" - FAC, ORG, ORG, ORG, GPE\n",
    "#\"How many\" - CARDINAL\n",
    "#\"How long\" - DATE\n",
    "#\"How much\" - MONEY\n",
    "#\"Why\" - \"because\"\n",
    "\n",
    "def check_NER(sentence, question_type):\n",
    "    output = False\n",
    "    ner_tag_dict = ner_tag_sentence(sentence)\n",
    "    if question_type == \"When\":\n",
    "        if (\"TIME\" in ner_tag_dict.values()) or (\"DATE\" in ner_tag_dict.values()):\n",
    "            output = True\n",
    "    elif question_type == \"Who\":\n",
    "        if (\"PERSON\" in ner_tag_dict.values()):\n",
    "            output = True\n",
    "    elif question_type == \"Where\":  \n",
    "        if (\"FAC\" in ner_tag_dict.values()) or (\"ORG\" in ner_tag_dict.values()) or (\"LOC\" in ner_tag_dict.values()):\n",
    "            output = True\n",
    "    elif question_type == \"How much\":\n",
    "        if (\"MONEY\" in ner_tag_dict.values()):\n",
    "            output = True\n",
    "    elif question_type == \"How long\":\n",
    "        if (\"DATE\" in ner_tag_dict.values()):\n",
    "            output = True\n",
    "    elif question_type == \"How many\":\n",
    "        if (\"CARDINAL\" in ner_tag_dict.values()):\n",
    "            output = True\n",
    "    elif question_type == \"How often\":\n",
    "        if (\"CARDINAL\" in ner_tag_dict.values()):\n",
    "            output = True\n",
    "    elif question_type == \"Why\":\n",
    "        if (\"because\" in sentence) or (\"due to\" in sentence) or (\"Due to\" in sentence):\n",
    "            output = True\n",
    "    else:\n",
    "        for aux in auxiliary_verbs:\n",
    "            aux_cap = aux[0].upper() + aux[1:]\n",
    "            if aux or aux_cap in sentence:\n",
    "                output = True\n",
    "    return output\n",
    "\n",
    "def checkSentenceType(sentence, dep_dict, ner_tag_dict, root):\n",
    "    possible_types = set()\n",
    "    if (\"TIME\" in ner_tag_dict.values()) or (\"DATE\" in ner_tag_dict.values()):\n",
    "        possible_types.add(\"When\")\n",
    "    if (\"PERSON\" in ner_tag_dict.values()):\n",
    "        possible_types.add(\"Who\")\n",
    "    if (\"FAC\" in ner_tag_dict.values()) or (\"ORG\" in ner_tag_dict.values()) or (\"LOC\" in ner_tag_dict.values()) or (\"GPE\" in ner_tag_dict.values()):\n",
    "        possible_types.add(\"Where\")\n",
    "    if (\"MONEY\" in ner_tag_dict.values()):\n",
    "        possible_types.add(\"How much\")\n",
    "    if (\"DATE\" in ner_tag_dict.values()):\n",
    "        possible_types.add(\"How long\")\n",
    "    if (\"CARDINAL\" in ner_tag_dict.values()):\n",
    "        possible_types.add(\"How many\")\n",
    "        possible_types.add(\"How often\")\n",
    "    if (\"because\" in sentence) or (\"due to\" in sentence) or (\"Due to\" in sentence) or (\"since\" in sentence):\n",
    "        possible_types.add(\"Why\")\n",
    "    aux_verbs = {\"are\", \"is\", \"was\", \"were\", \"shall\", \"do\", \"does\", \"did\", \n",
    "                 \"can\", \"could\", \"have\", \"need\", \"should\", \"will\", \"would\",\n",
    "                 \"must\", \"may\", \"might\", \"cannot\"}\n",
    "    if root in aux_verbs:\n",
    "        possible_types.add(\"What\")\n",
    "    for dep in dep_dict.values():\n",
    "        if dep[0] == 'nsubj':\n",
    "            possible_types.add(\"What\")\n",
    "    return possible_types\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"It is based on the novel of the same name by J. K. Rowling.\"\n",
    "# sentence = \"The story takes place in Hollywood, between 1927 and 1932, and focuses on the relationship of an older silent film star and a rising young actress as silent cinema falls out of fashion and is replaced by the 'talkies'.\"\n",
    "# sentence = \"The film, which is the third instalment in the Harry Potter film series, was written by Steve Kloves and produced by Chris Columbus (director of the first two instalments), David Heyman, and Mark Radcliffe.\"\n",
    "# sentence = \"The film stars Daniel Radcliffe as Harry Potter, alongside Rupert Grint and Emma Watson as Harry's best friends Ron Weasley and Hermione Granger.\"\n",
    "sentence = \"However, it was, at the time, the best-reviewed film of the series and currently the second-best-reviewed film of the franchise according to review aggregator Rotten Tomatoes.\"\n",
    "nlp_doc = nlp(sentence)\n",
    "dep_dict, root = dependency_dict(nlp_doc)\n",
    "ner_tag_dict = ner_tag_sentence(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'However': ('advmod', 'was', 'AUX', []),\n",
       " ',': ('punct', 'was', 'AUX', []),\n",
       " 'it': ('nsubj', 'was', 'AUX', []),\n",
       " 'was': ('ROOT', 'was', 'AUX', [However, ,, it, ,, at, ,, film, .]),\n",
       " 'at': ('prep', 'was', 'AUX', [time]),\n",
       " 'the': ('det', 'franchise', 'NOUN', []),\n",
       " 'time': ('pobj', 'at', 'ADP', [the]),\n",
       " 'best': ('advmod', 'reviewed', 'VERB', []),\n",
       " '-': ('punct', 'reviewed', 'VERB', []),\n",
       " 'reviewed': ('amod', 'film', 'NOUN', [second, -, best, -]),\n",
       " 'film': ('conj', 'film', 'NOUN', [currently, the, reviewed, of]),\n",
       " 'of': ('prep', 'film', 'NOUN', [franchise]),\n",
       " 'series': ('pobj', 'of', 'ADP', [the]),\n",
       " 'and': ('cc', 'film', 'NOUN', []),\n",
       " 'currently': ('advmod', 'film', 'NOUN', []),\n",
       " 'second': ('advmod', 'reviewed', 'VERB', []),\n",
       " 'franchise': ('pobj', 'of', 'ADP', [the]),\n",
       " 'according': ('prep', 'film', 'NOUN', [review]),\n",
       " 'to': ('aux', 'review', 'NOUN', []),\n",
       " 'review': ('pcomp', 'according', 'VERB', [to, aggregator]),\n",
       " 'aggregator': ('dobj', 'review', 'NOUN', []),\n",
       " 'Rotten': ('compound', 'Tomatoes', 'PROPN', []),\n",
       " 'Tomatoes': ('appos', 'film', 'NOUN', [Rotten]),\n",
       " '.': ('punct', 'was', 'AUX', [])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'second': 'ORDINAL', 'Rotten Tomatoes': 'PERSON'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'What', 'Who'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkSentenceType(sentence, dep_dict, ner_tag_dict, root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateQuestions(object):\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\ttextfile = \"test.txt\"\n",
    "\t\tself.nlp = spacy.load('en_core_web_sm')\n",
    "\t\tself.asker = Asking.Asking(textfile)\n",
    "\t\tself.parser = Parser.Parser(textfile)\n",
    "\n",
    "\tdef checkSentenceType(self, sentence, dep_dict, ner_tag_dict, root):\n",
    "\t\tpossible_types = set()\n",
    "\t\tif (\"TIME\" in ner_tag_dict.values()) or (\n",
    "\t\t\t\t\"DATE\" in ner_tag_dict.values()):\n",
    "\t\t\tpossible_types.add(\"When\")\n",
    "\t\tif (\"PERSON\" in ner_tag_dict.values()):\n",
    "\t\t\tpossible_types.add(\"Who\")\n",
    "\t\tif (\"FAC\" in ner_tag_dict.values()) or (\n",
    "\t\t\t\t\"ORG\" in ner_tag_dict.values()) or (\n",
    "\t\t\t\t\"LOC\" in ner_tag_dict.values()) or (\n",
    "\t\t\t\t\"GPE\" in ner_tag_dict.values()):\n",
    "\t\t\tpossible_types.add(\"Where\")\n",
    "\t\tif (\"MONEY\" in ner_tag_dict.values()):\n",
    "\t\t\tpossible_types.add(\"How much\")\n",
    "\t\tif (\"DATE\" in ner_tag_dict.values()):\n",
    "\t\t\tpossible_types.add(\"How long\")\n",
    "\t\tif (\"CARDINAL\" in ner_tag_dict.values()):\n",
    "\t\t\tpossible_types.add(\"How many\")\n",
    "\t\t\tpossible_types.add(\"How often\")\n",
    "\t\tif (\"because\" in sentence) or (\"due to\" in sentence) or (\n",
    "\t\t\t\t\"Due to\" in sentence) or (\"since\" in sentence):\n",
    "\t\t\tpossible_types.add(\"Why\")\n",
    "\t\taux_verbs = {\"are\", \"is\", \"was\", \"were\", \"shall\", \"do\", \"does\", \"did\",\n",
    "\t\t\t\t\t \"can\", \"could\", \"have\", \"need\", \"should\", \"will\", \"would\",\n",
    "\t\t\t\t\t \"must\", \"may\", \"might\", \"cannot\"}\n",
    "\t\tif root in aux_verbs:\n",
    "\t\t\tpossible_types.add(\"What\")\n",
    "\t\tfor dep in dep_dict.values():\n",
    "\t\t\tif dep[0] == 'nsubj':\n",
    "\t\t\t\tpossible_types.add(\"What\")\n",
    "\t\treturn possible_types\n",
    "\n",
    "\tdef generateQuestions(self, limit):\n",
    "\t\tpossible_questions = set()\n",
    "\t\tfor sentence in self.parser.text:\n",
    "\t\t\tprint(sentence)\n",
    "\t\t\tnlp_doc = self.nlp(sentence)\n",
    "\t\t\tpos_tags = self.parser.pos_tag_sentence(sentence)\n",
    "\t\t\ttoken_dict, root = self.parser.dependency_dict(nlp_doc)\n",
    "\t\t\tner_tags = self.parser.ner_tag_sentence(sentence)\n",
    "\t\t\tlemma_dict = self.parser.getTokenLemma(nlp_doc)\n",
    "\t\t\ttype_dict = {\"How many\": self.asker.howManyQ(sentence, ner_tags,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\ttoken_dict, pos_tags, root),\n",
    "\t\t\t\t\t\t \"Who\": self.asker.whoQ(sentence, ner_tags, token_dict),\n",
    "\t\t\t\t\t\t \"How much\": self.asker.howMuchQ(sentence, nlp_doc, ner_tags,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t  token_dict, root, pos_tags),\n",
    "\t\t\t\t\t\t \"How often\": self.asker.howOftenQ(sentence, ner_tags, token_dict,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tpos_tags, root),\n",
    "\t\t\t\t\t\t \"Why\": self.asker.whyQ(sentence, nlp_doc, ner_tags, token_dict,\n",
    "\t\t\t\t\t\t\t\t\t\t\t pos_tags, root),\n",
    "\t\t\t\t\t\t \"Where\": self.asker.whereQ(sentence, token_dict, pos_tags),\n",
    "\t\t\t\t\t\t \"What\": self.asker.whatQ(sentence, token_dict, root, pos_tags,\n",
    "\t\t\t\t\t\t\t\t\t\t\t   lemma_dict),\n",
    "\t\t\t\t\t\t \"When\": self.asker.whenQ(sentence, ner_tags, root, nlp_doc,\n",
    "\t\t\t\t\t\t\t\t\t\t\t   pos_tags)}\n",
    "\n",
    "\t\t\t# generate question outputs\n",
    "\t\t\ttry:\n",
    "\t\t\t\tpossible_types = self.checkSentenceType(sentence, token_dict,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tner_tags, root)\n",
    "\t\t\t\tfor type in possible_types:\n",
    "\t\t\t\t\tquestion = type_dict[type]\n",
    "\t\t\t\t\tif self.isValidQuestion(question):\n",
    "\t\t\t\t\t\tprint(question)\n",
    "\t\t\t\t\t\tpossible_questions.add(question)\n",
    "\t\t\t\t\tbinary_output = self.asker.binaryQ(sentence, root)\n",
    "\t\t\t\tif self.isValidQuestion(binary_output):\n",
    "\t\t\t\t\tprint(binary_output)\n",
    "\t\t\t\t\tpossible_questions.add(binary_output)\n",
    "\t\t\texcept:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t# limit amount of questions to be generated\n",
    "\t\t\tif len(possible_questions) >= limit:\n",
    "\t\t\t\treturn possible_questions\n",
    "\t\treturn possible_questions\n",
    "\n",
    "\t# check if generated question is valid\n",
    "\tdef isValidQuestion(self, question):\n",
    "\t\treturn question != None and len(question) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = GenerateQuestions()\n",
    "generator.generateQuestions(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
