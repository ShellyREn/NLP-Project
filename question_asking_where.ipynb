{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "textfile = \"data/set4/a7.txt\"\n",
    "#put entire text file into a list of sentences\n",
    "text = []\n",
    "with open(textfile, \"r\") as f:\n",
    "\tfor line in f:\n",
    "\t\tline = line.split('. ')\n",
    "\t\tif len(line) != 0:\n",
    "\t\t\ttemp = line[0].strip('\\n')\n",
    "\t\t\tif len(temp) != 0:\n",
    "\t\t\t\ttext.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi y name\n"
     ]
    }
   ],
   "source": [
    "print(nlp(\"hi y name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [('h', 'X', 'LS', 'ROOT', False)], 1: [('e', 'VERB', 'VB', 'ROOT', False)], 2: [('l', 'NOUN', 'NN', 'ROOT', False)], 3: [('l', 'NOUN', 'NN', 'ROOT', False)], 4: [('o', 'INTJ', 'UH', 'ROOT', False)], 5: [(' ', 'SPACE', '_SP', 'ROOT', False)], 6: [('m', 'VERB', 'VBP', 'ROOT', False)], 7: [('y', 'PROPN', 'NNP', 'ROOT', False)], 8: [(' ', 'SPACE', '_SP', 'ROOT', False)], 9: [('n', 'ADV', 'RB', 'ROOT', False)], 10: [('a', 'DET', 'DT', 'ROOT', True)], 11: [('m', 'VERB', 'VBP', 'ROOT', False)], 12: [('e', 'VERB', 'VB', 'ROOT', False)], 13: [(' ', 'SPACE', '_SP', 'ROOT', False)], 14: [('i', 'PRON', 'PRP', 'ROOT', True)], 15: [('s', 'VERB', 'VBZ', 'ROOT', False)], 16: [(' ', 'SPACE', '_SP', 'ROOT', False)], 17: [('L', 'NOUN', 'NN', 'ROOT', False)], 18: [('a', 'DET', 'DT', 'ROOT', True)], 19: [('u', 'NOUN', 'NN', 'ROOT', False)], 20: [('r', 'NOUN', 'NN', 'ROOT', False)], 21: [('a', 'DET', 'DT', 'ROOT', True)]}\n"
     ]
    }
   ],
   "source": [
    "print(pos_tag_lst(\"hello my name is Laura\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (<ipython-input-10-855aa09a104e>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-855aa09a104e>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    print(doc)\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "def pos_tag_lst(text):\n",
    "\t#list of sentences\n",
    "\tPOS_tag_dict = dict()\n",
    "\tfor i,line in enumerate(text):\n",
    "\t\ttags = []\n",
    "\t\tdoc = nlp(str(line))\n",
    "        print(doc)\n",
    "\t\tfor token in doc:\n",
    "#             print(doc)\n",
    "#             print(token)\n",
    "\t\t\ttags.append((token.text, token.pos_, token.tag_, token.dep_, token.is_stop))\n",
    "\t\tif len(tags) != 0:\n",
    "\t\t\tPOS_tag_dict[i] = tags\n",
    "\treturn POS_tag_dict\n",
    "\n",
    "def pos_tag_sentence(sentence):\n",
    "\t#list of sentences\n",
    "\tPOS_tag_dict = dict()\n",
    "\ttext = sentence.split()\n",
    "\tfor line in text:\n",
    "\t\ttags = []\n",
    "\t\tdoc = nlp(str(line))\n",
    "\t\tfor token in doc:\n",
    "\t\t\ttags.append((token.pos_, token.tag_, token.dep_, token.is_stop, ))\n",
    "\t\tif len(tags) != 0:\n",
    "\t\t\tPOS_tag_dict[token.text] = tags[0]\n",
    "\treturn POS_tag_dict\n",
    "\n",
    "#Token dict\n",
    "def dependency_dict(doc):\n",
    "\tout = dict()\n",
    "\troot = ''\n",
    "\tfor token in doc:\n",
    "\t\tout[token.text] = (token.dep_, token.head.text, token.head.pos_,[child for child in token.children])\n",
    "\t\tif token.dep_ == \"ROOT\":\n",
    "\t\t\troot = token.text\n",
    "\treturn out, root\n",
    "\n",
    "# NER tagging\n",
    "def ner_tag(text):\n",
    "\tNER_tag_dict = dict()\n",
    "\tfor i,line in enumerate(text):\n",
    "\t\ttags = []\n",
    "\t\tdoc = nlp(str(line))\n",
    "\n",
    "\t\tfor ent in doc.ents:\n",
    "\t\t\t# print(ent.text +'-' + ent.label_ + '\\n')\n",
    "\t\t\ttags.append(ent.text +'-' + ent.label_)\n",
    "\t\tif len(tags) != 0:\n",
    "\t\t\tNER_tag_dict[i] = tags\n",
    "\treturn NER_tag_dict\n",
    "\n",
    "def ner_tag_sentence(sentence):\n",
    "\tdoc = nlp(str(sentence))\n",
    "\tNER_tag_dict = dict()\n",
    "\ttags = []\n",
    "\tfor ent in doc.ents:\n",
    "\t\t# print(ent.text +'-' + ent.label_ + '\\n')\n",
    "\t\tNER_tag_dict[ent.text] = ent.label_\n",
    "\treturn NER_tag_dict\n",
    "\n",
    "\n",
    "#check tense of verb\n",
    "def check_tense(root, pos_dict):\n",
    "\ttag = pos_dict[root][1]\n",
    "\tif tag == \"VB\":\n",
    "\t\treturn \"do\"\n",
    "\telif tag == \"VBD\":\n",
    "\t\treturn \"did\"\n",
    "\telif tag == \"VBG\":\n",
    "\t\treturn \"doing\"\n",
    "\telif tag == \"VBN\":\n",
    "\t\treturn \"done\"\n",
    "\telif tag == \"VBP\":\n",
    "\t\treturn \"do\"\n",
    "\telif tag == \"VBZ\":\n",
    "\t\treturn \"does\"\n",
    "\telse:\n",
    "\t\treturn None\n",
    "\n",
    "# return dictionary of lemmas in sentence\n",
    "def getTokenLemma(nlp_doc):\n",
    "\tlemmas = {}\n",
    "\tfor token in nlp_doc:\n",
    "\t\tlemmas[str(token)] = token.lemma_\n",
    "\treturn lemmas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whereQ(sentence, dep_dict, root):\n",
    "    output = ''\n",
    "    verbs = ['was', 'is', 'were']\n",
    "    foundVerb = False\n",
    "    foundVerbInd = 0\n",
    "    # find tense \n",
    "    pos_tags = pos_tag_sentence(sentence)\n",
    "    seenWhere = False\n",
    "    foundWhereInd = 0\n",
    "    whereInd = 0\n",
    "    tense = None\n",
    "    for word in sentence.split():\n",
    "        if word == 'where':\n",
    "            seenWhere = True\n",
    "            foundWhereInd = whereInd\n",
    "            verb = dep_dict[word][1]\n",
    "            if pos_tags[verb][0] == 'VERB':\n",
    "                tense = check_tense(verb, pos_tags)\n",
    "            elif verb in verbs: # if tense is was, is, were\n",
    "                tense = verb\n",
    "                foundVerb = True\n",
    "                foundVerbInd = sentence.split().index(verb)\n",
    "            break\n",
    "        whereInd += 1\n",
    "    if tense == None: # not able to create question from sentence\n",
    "        return \"No question\"\n",
    "    output += f'Where {tense} '\n",
    "    ind = foundWhereInd\n",
    "    if foundVerb:\n",
    "        ind = foundVerbInd\n",
    "    for word in sentence.split()[ind+1:]:\n",
    "        output += word + \" \"    \n",
    "    return output[:-2] + \"?\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'This': ('nsubj', 'leads', 'VERB', []), 'leads': ('ROOT', 'leads', 'VERB', [This, trio, to, .]), 'the': ('det', 'dog', 'NOUN', []), 'trio': ('dobj', 'leads', 'VERB', [the]), 'to': ('prep', 'passage', 'NOUN', [Shack]), 'an': ('det', 'Animagus', 'PROPN', []), 'underground': ('amod', 'passage', 'NOUN', []), 'passage': ('pobj', 'to', 'ADP', [an, underground, to]), 'Shrieking': ('compound', 'Shack', 'PROPN', []), 'Shack': ('pobj', 'to', 'ADP', [the, Shrieking, ,, discover]), ',': ('punct', 'Sirius', 'PROPN', []), 'where': ('advmod', 'discover', 'VERB', []), 'they': ('nsubj', 'discover', 'VERB', []), 'discover': ('relcl', 'Shack', 'PROPN', [where, they, is]), 'that': ('mark', 'is', 'AUX', []), 'dog': ('nsubj', 'is', 'AUX', [the]), 'is': ('relcl', 'Sirius', 'PROPN', [who, Animagus]), 'actually': ('advmod', 'is', 'AUX', []), 'Sirius': ('attr', 'is', 'AUX', [,, is]), 'who': ('nsubj', 'is', 'VERB', []), 'Animagus': ('attr', 'is', 'VERB', [an]), '.': ('punct', 'leads', 'VERB', [])} leads\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This leads the trio to an underground passage to the Shrieking Shack, where they discover that the dog is actually Sirius, who is an Animagus.\"\n",
    "dep_dict1, root1 = dependency_dict(nlp(sentence))\n",
    "print(dep_dict1, root1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'He': ('nsubj', 'was', 'AUX', []), 'was': ('ROOT', 'was', 'AUX', [He, in, .]), 'in': ('prep', 'was', 'AUX', [underground]), 'the': ('det', 'underground', 'NOUN', []), 'underground': ('pobj', 'in', 'ADP', [the, ,, were]), ',': ('punct', 'underground', 'NOUN', []), 'where': ('advmod', 'were', 'VERB', []), 'there': ('expl', 'were', 'VERB', []), 'were': ('relcl', 'underground', 'NOUN', [where, there, lots]), 'lots': ('attr', 'were', 'VERB', [of]), 'of': ('prep', 'lots', 'NOUN', [tea]), 'tea': ('pobj', 'of', 'ADP', []), '.': ('punct', 'was', 'AUX', [])} was\n"
     ]
    }
   ],
   "source": [
    "sentence2 = \"He was in the underground, where there were lots of tea.\"\n",
    "dep_dict2, root2 = dependency_dict(nlp(sentence2))\n",
    "print(dep_dict2, root2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'He': ('PRON', 'PRP', 'ROOT', True),\n",
       " 'was': ('AUX', 'VBD', 'ROOT', True),\n",
       " 'in': ('ADP', 'IN', 'ROOT', True),\n",
       " 'the': ('DET', 'DT', 'ROOT', True),\n",
       " ',': ('ADV', 'RB', 'ROOT', False),\n",
       " 'where': ('ADV', 'WRB', 'ROOT', True),\n",
       " 'there': ('ADV', 'RB', 'ROOT', True),\n",
       " 'were': ('AUX', 'VBD', 'ROOT', True),\n",
       " 'lots': ('NOUN', 'NNS', 'ROOT', False),\n",
       " 'of': ('ADP', 'IN', 'ROOT', True),\n",
       " '.': ('NOUN', 'NN', 'ROOT', False)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag_sentence(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'This': ('DET', 'DT', 'ROOT', True),\n",
       " 'leads': ('VERB', 'VBZ', 'ROOT', False),\n",
       " 'the': ('DET', 'DT', 'ROOT', True),\n",
       " 'trio': ('NOUN', 'NN', 'ROOT', False),\n",
       " 'to': ('PART', 'TO', 'ROOT', True),\n",
       " 'an': ('DET', 'DT', 'ROOT', True),\n",
       " 'underground': ('ADV', 'RB', 'ROOT', False),\n",
       " 'passage': ('NOUN', 'NN', 'ROOT', False),\n",
       " 'Shrieking': ('VERB', 'VBG', 'ROOT', False),\n",
       " ',': ('PROPN', 'NNP', 'ROOT', False),\n",
       " 'where': ('ADV', 'WRB', 'ROOT', True),\n",
       " 'they': ('PRON', 'PRP', 'ROOT', True),\n",
       " 'discover': ('VERB', 'VB', 'ROOT', False),\n",
       " 'that': ('DET', 'DT', 'ROOT', True),\n",
       " 'dog': ('NOUN', 'NN', 'ROOT', False),\n",
       " 'is': ('AUX', 'VBZ', 'ROOT', True),\n",
       " 'actually': ('ADV', 'RB', 'ROOT', False),\n",
       " 'who': ('PRON', 'WP', 'ROOT', True),\n",
       " '.': ('PROPN', 'NNP', 'ROOT', False)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where do they discover that the dog is actually Sirius, who is an Animagus?\n"
     ]
    }
   ],
   "source": [
    "print(whereQ(sentence, dep_dict1, root1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where were lots of tea?\n"
     ]
    }
   ],
   "source": [
    "print(whereQ(sentence2, dep_dict2, root2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
