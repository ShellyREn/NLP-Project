{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "signal-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-mississippi",
   "metadata": {},
   "source": [
    "# TIPS\n",
    "1. Delete everything inside a bracket first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "searching-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "textfile = \"data/set4/a7.txt\"\n",
    "\n",
    "sentence1 = \"Harry Potter and the Prisoner of Azkaban is a 2004 fantasy film directed by Alfonso Cuarón and distributed by Warner Bros.\"\n",
    "sentence2 = \"Harry Potter has been spending another unhappy summer with the Dursleys.\"\n",
    "sentence3 = \"The film was produced by La Petite Reine and ARP Sélection for 13.47 million dollars.\"\n",
    "sentence4 = \"The film took them 13.47 million dollars.\"\n",
    "\n",
    "\n",
    "doc1 = nlp(sentence1)\n",
    "doc2 = nlp(sentence2)\n",
    "doc3 = nlp(sentence3)\n",
    "doc4 = nlp(sentence4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "painful-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile = \"data/set4/a7.txt\"\n",
    "\n",
    "#put entire text file into a list of sentences\n",
    "text = []\n",
    "with open(textfile, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.split('. ')\n",
    "        if len(line) != 0:\n",
    "            temp = line[0].strip('\\n')\n",
    "            if len(temp) != 0:\n",
    "                text.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-script",
   "metadata": {},
   "source": [
    "# POS tagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "professional-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag_lst(text):\n",
    "    #list of sentences\n",
    "    POS_tag_dict = dict()\n",
    "    for i,line in enumerate(text):\n",
    "        tags = []\n",
    "        doc = nlp(str(line))\n",
    "        for token in doc:\n",
    "            tags.append((token.text, token.pos_, token.tag_, token.dep_, token.is_stop))\n",
    "        if len(tags) != 0:\n",
    "            POS_tag_dict[i] = tags\n",
    "    return POS_tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "scenic-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag_sentence(sentence):\n",
    "    #list of sentences\n",
    "    POS_tag_dict = dict()\n",
    "    text = sentence.split()\n",
    "    for line in text:\n",
    "        tags = []\n",
    "        doc = nlp(str(line))\n",
    "        for token in doc:\n",
    "            tags.append((token.pos_, token.tag_, token.dep_, token.is_stop, ))\n",
    "        if len(tags) != 0:\n",
    "            POS_tag_dict[token.text] = tags[0]\n",
    "    return POS_tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "controlled-deviation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The': ('DET', 'DT', 'ROOT', True),\n",
       " 'film': ('NOUN', 'NN', 'ROOT', False),\n",
       " 'was': ('AUX', 'VBD', 'ROOT', True),\n",
       " 'produced': ('VERB', 'VBD', 'ROOT', False),\n",
       " 'by': ('ADP', 'IN', 'ROOT', True),\n",
       " 'La': ('PROPN', 'NNP', 'ROOT', False),\n",
       " 'Petite': ('ADJ', 'JJ', 'ROOT', False),\n",
       " 'Reine': ('VERB', 'VB', 'ROOT', False),\n",
       " 'and': ('CCONJ', 'CC', 'ROOT', True),\n",
       " 'ARP': ('PROPN', 'NNP', 'ROOT', False),\n",
       " 'Sélection': ('NOUN', 'NN', 'ROOT', False),\n",
       " 'for': ('ADP', 'IN', 'ROOT', True),\n",
       " '13.47': ('NUM', 'CD', 'ROOT', False),\n",
       " 'million': ('NUM', 'CD', 'ROOT', False),\n",
       " '.': ('NOUN', 'NNS', 'ROOT', False)}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag_sentence(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "convinced-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = pos_tag_lst(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-joyce",
   "metadata": {},
   "source": [
    "# Dependency Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "burning-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Token dict \n",
    "def dependency_dict(doc):\n",
    "    out = dict()\n",
    "    root = ''\n",
    "    for token in doc:\n",
    "        out[token.text] = (token.dep_, token.head.text, token.head.pos_,[child for child in token.children])\n",
    "        if token.dep_ == \"ROOT\":\n",
    "            root = token.text\n",
    "    return out, root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prerequisite-holly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Harry': ('compound', 'Potter', 'PROPN', []),\n",
       "  'Potter': ('nsubj', 'is', 'AUX', [Harry, and, Prisoner]),\n",
       "  'and': ('cc', 'directed', 'VERB', []),\n",
       "  'the': ('det', 'Prisoner', 'PROPN', []),\n",
       "  'Prisoner': ('conj', 'Potter', 'PROPN', [the, of]),\n",
       "  'of': ('prep', 'Prisoner', 'PROPN', [Azkaban]),\n",
       "  'Azkaban': ('pobj', 'of', 'ADP', []),\n",
       "  'is': ('ROOT', 'is', 'AUX', [Potter, film]),\n",
       "  'a': ('det', 'film', 'NOUN', []),\n",
       "  '2004': ('nummod', 'film', 'NOUN', []),\n",
       "  'fantasy': ('compound', 'film', 'NOUN', []),\n",
       "  'film': ('attr', 'is', 'AUX', [a, 2004, fantasy, directed]),\n",
       "  'directed': ('acl', 'film', 'NOUN', [by, and, distributed]),\n",
       "  'by': ('agent', 'distributed', 'VERB', [Bros.]),\n",
       "  'Alfonso': ('compound', 'Cuarón', 'PROPN', []),\n",
       "  'Cuarón': ('pobj', 'by', 'ADP', [Alfonso]),\n",
       "  'distributed': ('conj', 'directed', 'VERB', [by]),\n",
       "  'Warner': ('compound', 'Bros.', 'PROPN', []),\n",
       "  'Bros.': ('pobj', 'by', 'ADP', [Warner])},\n",
       " 'is')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_Dict1, root1 = dependency_dict(doc1)\n",
    "token_Dict1, root1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ongoing-grenada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Harry': ('compound', 'Potter', 'PROPN', []),\n",
       "  'Potter': ('nsubj', 'spending', 'VERB', [Harry]),\n",
       "  'has': ('aux', 'spending', 'VERB', []),\n",
       "  'been': ('aux', 'spending', 'VERB', []),\n",
       "  'spending': ('ROOT',\n",
       "   'spending',\n",
       "   'VERB',\n",
       "   [Potter, has, been, summer, with, .]),\n",
       "  'another': ('det', 'summer', 'NOUN', []),\n",
       "  'unhappy': ('amod', 'summer', 'NOUN', []),\n",
       "  'summer': ('dobj', 'spending', 'VERB', [another, unhappy]),\n",
       "  'with': ('prep', 'spending', 'VERB', [Dursleys]),\n",
       "  'the': ('det', 'Dursleys', 'PROPN', []),\n",
       "  'Dursleys': ('pobj', 'with', 'ADP', [the]),\n",
       "  '.': ('punct', 'spending', 'VERB', [])},\n",
       " 'spending')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_Dict2, root2 = dependency_dict(doc2)\n",
    "token_Dict2, root2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "classical-agent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'The': ('det', 'film', 'NOUN', []),\n",
       "  'film': ('nsubjpass', 'produced', 'VERB', [The]),\n",
       "  'was': ('auxpass', 'produced', 'VERB', []),\n",
       "  'produced': ('ROOT', 'produced', 'VERB', [film, was, by, for, .]),\n",
       "  'by': ('agent', 'produced', 'VERB', [Reine]),\n",
       "  'La': ('compound', 'Reine', 'PROPN', []),\n",
       "  'Petite': ('compound', 'Reine', 'PROPN', []),\n",
       "  'Reine': ('pobj', 'by', 'ADP', [La, Petite, and, Sélection]),\n",
       "  'and': ('cc', 'Reine', 'PROPN', []),\n",
       "  'ARP': ('compound', 'Sélection', 'PROPN', []),\n",
       "  'Sélection': ('conj', 'Reine', 'PROPN', [ARP]),\n",
       "  'for': ('prep', 'produced', 'VERB', [dollars]),\n",
       "  '13.47': ('compound', 'million', 'NUM', []),\n",
       "  'million': ('nummod', 'dollars', 'NOUN', [13.47]),\n",
       "  'dollars': ('pobj', 'for', 'ADP', [million]),\n",
       "  '.': ('punct', 'produced', 'VERB', [])},\n",
       " 'produced')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_Dict3, root3 = dependency_dict(doc3)\n",
    "token_Dict3, root3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-twenty",
   "metadata": {},
   "source": [
    "# NER Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "clean-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_tag(text):\n",
    "    NER_tag_dict = dict()\n",
    "    for i,line in enumerate(text):\n",
    "        tags = []\n",
    "        doc = nlp(str(line))\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            # print(ent.text +'-' + ent.label_ + '\\n')\n",
    "            tags.append(ent.text +'-' + ent.label_)\n",
    "        if len(tags) != 0:\n",
    "            NER_tag_dict[i] = tags\n",
    "    return NER_tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "collaborative-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_tag_sentence(sentence):\n",
    "    doc = nlp(str(sentence))\n",
    "    NER_tag_dict = dict()\n",
    "    tags = []\n",
    "    for ent in doc.ents:\n",
    "        # print(ent.text +'-' + ent.label_ + '\\n')\n",
    "        NER_tag_dict[ent.text] = ent.label_\n",
    "    return NER_tag_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-planning",
   "metadata": {},
   "source": [
    "# Binary Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "anonymous-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_verbs = [\"am\", \"is\", \"are\", \"was\", \"were\", \"shall\", \"do\", \"does\", \"did\",\"can\", \"could\", \"have\", \"need\", \"should\", \"will\", \"would\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prompt-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: a single sentence, with its dependency dict and root word\n",
    "def binaryQ(sentence, token_dict, root):\n",
    "    output = ''\n",
    "    if root in auxiliary_verbs:\n",
    "        output += root.capitalize() + ' '\n",
    "    for k in sentence.split():\n",
    "        if k != root:\n",
    "            output += k + ' '\n",
    "    output = output[:-2]+ '?'\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "indie-disaster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Harry Potter and the Prisoner of Azkaban a 2004 fantasy film directed by Alfonso Cuarón and distributed by Warner Bros?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binaryQ(sentence1, token_Dict1, root1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-rings",
   "metadata": {},
   "source": [
    "# Who Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "iraqi-stopping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Harry': [('PROPN', 'NNP', 'ROOT', False)],\n",
       " 'Potter': [('NOUN', 'NN', 'ROOT', False)],\n",
       " 'has': [('VERB', 'VBZ', 'ROOT', True)],\n",
       " 'been': [('VERB', 'VBN', 'ROOT', True)],\n",
       " 'spending': [('VERB', 'VBG', 'ROOT', False)],\n",
       " 'another': [('DET', 'DT', 'ROOT', True)],\n",
       " 'unhappy': [('ADJ', 'JJ', 'ROOT', False)],\n",
       " 'summer': [('NOUN', 'NN', 'ROOT', False)],\n",
       " 'with': [('ADP', 'IN', 'ROOT', True)],\n",
       " 'the': [('DET', 'DT', 'ROOT', True)],\n",
       " '.': [('PROPN', 'NNP', 'ROOT', False), ('PUNCT', '.', 'punct', False)]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag_sentence(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "catholic-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tag_dict2 = ner_tag_sentence(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "billion-bracket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Harry': ('compound', 'Potter', 'PROPN', []),\n",
       "  'Potter': ('nsubj', 'spending', 'VERB', [Harry]),\n",
       "  'has': ('aux', 'spending', 'VERB', []),\n",
       "  'been': ('aux', 'spending', 'VERB', []),\n",
       "  'spending': ('ROOT',\n",
       "   'spending',\n",
       "   'VERB',\n",
       "   [Potter, has, been, summer, with, .]),\n",
       "  'another': ('det', 'summer', 'NOUN', []),\n",
       "  'unhappy': ('amod', 'summer', 'NOUN', []),\n",
       "  'summer': ('dobj', 'spending', 'VERB', [another, unhappy]),\n",
       "  'with': ('prep', 'spending', 'VERB', [Dursleys]),\n",
       "  'the': ('det', 'Dursleys', 'PROPN', []),\n",
       "  'Dursleys': ('pobj', 'with', 'ADP', [the]),\n",
       "  '.': ('punct', 'spending', 'VERB', [])},\n",
       " 'spending')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependency_dict2, root2 = dependency_dict(doc2)\n",
    "dependency_dict2, root2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "congressional-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: a single sentence, and its ner tag dict and dependency dict\n",
    "#Who Question\n",
    "def whoQ(sentence, ner_tag_dict, dependency_dict):\n",
    "    #find PERSON tag\n",
    "    theName = ''\n",
    "    output = ''\n",
    "    for k in ner_tag_dict.keys():\n",
    "        if ner_tag_dict[k] == 'PERSON':\n",
    "            #check if is a subject\n",
    "            names = k.split()\n",
    "            for n in names:\n",
    "                print(dependency_dict[n])\n",
    "                if dependency_dict[n][0] == 'nsubj':\n",
    "                    theName = k\n",
    "    print(theName)\n",
    "    output = sentence.replace(theName, 'who')\n",
    "    output = output[:-1] + \"?\"\n",
    "    output = output[0].upper() + output[1:]\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "democratic-transport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('compound', 'Potter', 'PROPN', [])\n",
      "('nsubj', 'spending', 'VERB', [Harry])\n",
      "('pobj', 'with', 'ADP', [the])\n",
      "Harry Potter\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Who has been spending another unhappy summer with the Dursleys?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whoQ(sentence2, ner_tag_dict2, dependency_dict2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-clone",
   "metadata": {},
   "source": [
    "# How much Question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "nominated-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tag_dict3 = ner_tag_sentence(sentence3)\n",
    "dependency_dict3, root3 = dependency_dict(doc3)\n",
    "pos_tag_dict3 = pos_tag_sentence(sentence3)\n",
    "# \"The film was produced by La Petite Reine and ARP Sélection for 13.47 million euros.\" don't identify as MONEY\n",
    "# \"The film was produced by La Petite Reine and ARP Sélection for 13.47 million dollars.\"\n",
    "    # How much was the film produced by La Petite Reine and ARP Sélection?\n",
    "# \"The film costs 13.47 million dollars.\"\n",
    "    # How much does the film costs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "sacred-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tag_dict4 = ner_tag_sentence(sentence4)\n",
    "dependency_dict4, root4 = dependency_dict(doc4)\n",
    "pos_tag_dict4 = pos_tag_sentence(sentence4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fourth-invasion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'La Petite': 'PERSON', '13.47 million dollars': 'MONEY'},\n",
       " {'The': ('det', 'film', 'NOUN', []),\n",
       "  'film': ('nsubjpass', 'produced', 'VERB', [The]),\n",
       "  'was': ('auxpass', 'produced', 'VERB', []),\n",
       "  'produced': ('ROOT', 'produced', 'VERB', [film, was, by, for, .]),\n",
       "  'by': ('agent', 'produced', 'VERB', [Reine]),\n",
       "  'La': ('compound', 'Reine', 'PROPN', []),\n",
       "  'Petite': ('compound', 'Reine', 'PROPN', []),\n",
       "  'Reine': ('pobj', 'by', 'ADP', [La, Petite, and, Sélection]),\n",
       "  'and': ('cc', 'Reine', 'PROPN', []),\n",
       "  'ARP': ('compound', 'Sélection', 'PROPN', []),\n",
       "  'Sélection': ('conj', 'Reine', 'PROPN', [ARP]),\n",
       "  'for': ('prep', 'produced', 'VERB', [dollars]),\n",
       "  '13.47': ('compound', 'million', 'NUM', []),\n",
       "  'million': ('nummod', 'dollars', 'NOUN', [13.47]),\n",
       "  'dollars': ('pobj', 'for', 'ADP', [million]),\n",
       "  '.': ('punct', 'produced', 'VERB', [])},\n",
       " 'produced',\n",
       " {'The': [('DET', 'DT', 'ROOT', True)],\n",
       "  'film': [('NOUN', 'NN', 'ROOT', False)],\n",
       "  'was': [('AUX', 'VBD', 'ROOT', True)],\n",
       "  'produced': [('VERB', 'VBD', 'ROOT', False)],\n",
       "  'by': [('ADP', 'IN', 'ROOT', True)],\n",
       "  'La': [('PROPN', 'NNP', 'ROOT', False)],\n",
       "  'Petite': [('ADJ', 'JJ', 'ROOT', False)],\n",
       "  'Reine': [('VERB', 'VB', 'ROOT', False)],\n",
       "  'and': [('CCONJ', 'CC', 'ROOT', True)],\n",
       "  'ARP': [('PROPN', 'NNP', 'ROOT', False)],\n",
       "  'Sélection': [('NOUN', 'NN', 'ROOT', False)],\n",
       "  'for': [('ADP', 'IN', 'ROOT', True)],\n",
       "  '13.47': [('NUM', 'CD', 'ROOT', False)],\n",
       "  'million': [('NUM', 'CD', 'ROOT', False)],\n",
       "  '.': [('NOUN', 'NNS', 'ROOT', False), ('PUNCT', '.', 'punct', False)]})"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tag_dict3, dependency_dict3, root3, pos_tag_dict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "further-squad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'13.47 million dollars': 'MONEY'},\n",
       " {'The': ('det', 'film', 'NOUN', []),\n",
       "  'film': ('nsubj', 'took', 'VERB', [The]),\n",
       "  'took': ('ROOT', 'took', 'VERB', [film, them, dollars, .]),\n",
       "  'them': ('dative', 'took', 'VERB', []),\n",
       "  '13.47': ('compound', 'million', 'NUM', []),\n",
       "  'million': ('nummod', 'dollars', 'NOUN', [13.47]),\n",
       "  'dollars': ('dobj', 'took', 'VERB', [million]),\n",
       "  '.': ('punct', 'took', 'VERB', [])},\n",
       " 'took',\n",
       " {'The': ('DET', 'DT', 'ROOT', True),\n",
       "  'film': ('NOUN', 'NN', 'ROOT', False),\n",
       "  'took': ('VERB', 'VBD', 'ROOT', False),\n",
       "  'them': ('PRON', 'PRP', 'ROOT', True),\n",
       "  '13.47': ('NUM', 'CD', 'ROOT', False),\n",
       "  'million': ('NUM', 'CD', 'ROOT', False),\n",
       "  '.': ('NOUN', 'NNS', 'ROOT', False)})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tag_dict4, dependency_dict4, root4, pos_tag_dict4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-concentrate",
   "metadata": {},
   "source": [
    "VB verb, base form take\n",
    "VBD verb, past tense took\n",
    "VBG verb, gerund/present participle taking\n",
    "VBN verb, past participle taken\n",
    "VBP verb, sing. present, non-3d take\n",
    "VBZ verb, 3rd person sing. present takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "rapid-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check tense of verb\n",
    "def check_tense(root, pos_dict):\n",
    "    tag = pos_dict[root][1]\n",
    "    if tag == \"VB\":\n",
    "        return \"do\"\n",
    "    elif tag == \"VBD\":\n",
    "        return \"did\"\n",
    "    elif tag == \"VBG\":\n",
    "        return \"doing\"\n",
    "    elif tag == \"VBN\":\n",
    "        return \"done\"\n",
    "    elif tag == \"VBP\":\n",
    "        return \"do\"\n",
    "    elif tag == \"VBZ\":\n",
    "        return \"does\"\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "technological-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: a single sentence, and its ner tag dict and dependency dict\n",
    "#How much Question\n",
    "#The film was produced by La Petite Reine and ARP Sélection for 13.47 million dollars.\n",
    "#How much was the film produced by La Petite Reine and ARP Sélection?\n",
    "def howMuchQ(sentence, doc, ner_tag_dict, dependency_dict, root, pos_dict):\n",
    "    theMoney = \"\"\n",
    "    output = \"\"\n",
    "    theSubj = \"\"\n",
    "    for k in ner_tag_dict.keys():\n",
    "        if ner_tag_dict[k] == 'MONEY':\n",
    "            theMoney = k\n",
    "    #check passive tense \n",
    "    sentence_lst = sentence.split()\n",
    "    root_ind = sentence_lst.index(root)\n",
    "    root_token = doc[root_ind]\n",
    "    if root_ind != 0:\n",
    "        word_in_front_of_root = sentence_lst[root_ind -1] \n",
    "        #if it's passive tense\n",
    "        if dependency_dict[word_in_front_of_root][0] == 'auxpass':\n",
    "            root_aux = word_in_front_of_root\n",
    "            output += 'How much '+ root_aux + ' '\n",
    "            for n in dependency_dict:\n",
    "                if dependency_dict[n][0] == 'nsubjpass':\n",
    "                    theSubj = n    \n",
    "            words_before_subj = dependency_dict[theSubj][-1]\n",
    "            if len(words_before_subj) != 0:\n",
    "                output += str(words_before_subj[0]).lower() + ' '\n",
    "            output += theSubj + \"?\"\n",
    "        else: #if it's not passive tense\n",
    "            for n in dependency_dict:\n",
    "                if dependency_dict[n][0] == 'nsubj':\n",
    "                    theSubj = n  \n",
    "            output += 'How much '\n",
    "            #check tense\n",
    "            tense = check_tense(root, pos_dict)\n",
    "            if tense != None:\n",
    "                output += tense + ' '\n",
    "                #check subject\n",
    "                for n in dependency_dict:\n",
    "                    if dependency_dict[n][0] == 'nsubj':\n",
    "                        theSubj = n    \n",
    "                words_before_subj = dependency_dict[theSubj][-1]\n",
    "                if len(words_before_subj) != 0:\n",
    "                    output += str(words_before_subj[0]).lower() + ' '\n",
    "                output += theSubj + ' ' + root_token.lemma_ + \"?\"\n",
    "            else:\n",
    "                return None\n",
    "    return output\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "delayed-methodology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How much did the film take?'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "howMuchQ(sentence4, doc4, ner_tag_dict4, dependency_dict4, root4, pos_tag_dict4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cloudy-listing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How much was the film?'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "howMuchQ(sentence3, doc3, ner_tag_dict3, dependency_dict3, root3, pos_tag_dict3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-george",
   "metadata": {},
   "source": [
    "# Why Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify “because”, “since”, “for”, “due to”, “... result…”, “lead to”\n",
    "# NP VP because (of) B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-thong",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36] *",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
